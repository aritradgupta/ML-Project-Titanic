{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re as re\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (891, 12)\n",
      "Shape of test data: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "all_data = [train,test]\n",
    "print(\"Shape of training data:\", train.shape)\n",
    "print(\"Shape of test data:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin          687\n",
      "Age            177\n",
      "Embarked         2\n",
      "Fare             0\n",
      "Ticket           0\n",
      "Parch            0\n",
      "SibSp            0\n",
      "Sex              0\n",
      "Name             0\n",
      "Pclass           0\n",
      "Survived         0\n",
      "PassengerId      0\n",
      "dtype: int64\n",
      "Cabin          327\n",
      "Age             86\n",
      "Fare             1\n",
      "Embarked         0\n",
      "Ticket           0\n",
      "Parch            0\n",
      "SibSp            0\n",
      "Sex              0\n",
      "Name             0\n",
      "Pclass           0\n",
      "PassengerId      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    print(dataset.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "print (train[['Sex','Survived']].groupby(['Sex'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "print (train[['Pclass','Survived']].groupby(['Pclass'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "Age has some missing values so we will do some data cleaning and fill missing values as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age_Category  Survived\n",
      "0  (-0.08, 16.0]  0.522936\n",
      "1   (16.0, 32.0]  0.336980\n",
      "2   (32.0, 48.0]  0.408163\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    age_mean = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_count_null = dataset['Age'].isnull().sum()\n",
    "\n",
    "    age_random_list = np.random.randint(age_mean - age_std, age_mean + age_std, size=age_count_null)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "train['Age_Category'] = pd.cut(train['Age'],5)\n",
    "print(train[['Age_Category','Survived']].groupby(['Age_Category'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name\n",
    "Feature engineering with title of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.702703\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4    Rare  0.347826\n"
     ]
    }
   ],
   "source": [
    "def get_title(name):\n",
    "    title = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title:\n",
    "        return title.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in all_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "                                                   'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print(train[['Title','Survived']].groupby(['Title'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SibSp & Parch\n",
    "SibSp and Parch can be combined to make family size feature and also check number of people who were travelling alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp']+dataset['Parch']+1\n",
    "print(train[['FamilySize','Survived']].groupby(['FamilySize'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize']==1,'IsAlone'] = 1\n",
    "print(train[['IsAlone','Survived']].groupby(['IsAlone'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked\n",
    "This feature has some missing values and we fill them with the most common value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])\n",
    "print(train[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare\n",
    "This feature has some missing values and we fill them with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Fare_Category  Survived\n",
      "0   (-0.001, 7.91]  0.197309\n",
      "1   (7.91, 14.454]  0.303571\n",
      "2   (14.454, 31.0]  0.454955\n",
      "3  (31.0, 512.329]  0.581081\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['Fare_Category'] = pd.qcut(train['Fare'],4)\n",
    "print(train[['Fare_Category','Survived']].groupby(['Fare_Category'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone\n",
      "0         0       3    1    1     0         0      1        0\n",
      "1         1       1    0    2     3         1      3        0\n",
      "2         1       3    0    1     1         0      2        1\n",
      "3         1       1    0    2     3         0      3        0\n",
      "4         0       3    1    2     1         0      1        1\n",
      "5         0       3    1    1     1         2      1        1\n",
      "6         0       1    1    3     3         0      1        1\n",
      "7         0       3    1    0     2         0      4        0\n",
      "8         1       3    0    1     1         0      3        0\n",
      "9         1       2    0    0     2         1      3        0\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n",
    "                 'Parch', 'FamilySize']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['Age_Category', 'Fare_Category'], axis = 1)\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (train.head(10))\n",
    "\n",
    "train_d = train.drop(['Survived'],axis=1).values\n",
    "test_d  = test.values\n",
    "y = train['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import grid_search\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['linear', 'rbf']\n",
    "param_grid = {'kernel':kernels, 'C':cs, 'gamma':gammas}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(train_d, y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.819299791084\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=100, kernel='rbf', gamma=0.01)\n",
    "svc_score = cross_val_score(svc, train_d, y, cv=5)\n",
    "print(\"CV score is:\", svc_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.763302192683\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(3)\n",
    "knn_score = cross_val_score(knn, train_d, y, cv=5)\n",
    "print(\"CV score is:\", knn_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_samples_split': 9}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'min_samples_split' : np.arange(2,100),'max_depth': np.arange(1,30)}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(train_d,y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.818232689207\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=9, min_samples_split=9)\n",
    "dtree_score = cross_val_score(dtree, train_d, y, cv=5)\n",
    "print(\"CV score is:\", dtree_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": np.arange(2,20)\n",
    "            ,\"min_samples_split\" : np.arange(2,10)\n",
    "            ,\"n_estimators\" : [10]\n",
    "            ,\"min_samples_leaf\": np.arange(1,10)}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=-1, cv=5)\n",
    "grid_search.fit(train_d, y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.80815813393\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestClassifier(n_estimators=5000, max_depth=17, min_samples_leaf=3, min_samples_split=9)\n",
    "rfr_score = cross_val_score(rfr, train_d, y, cv=5)\n",
    "print(\"CV score is:\", rfr_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.796903276737\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada_score = cross_val_score(ada, train_d, y, cv=5)\n",
    "print(\"CV score is:\", ada_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.809307121424\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc_score = cross_val_score(gbc, train_d, y, cv=5)\n",
    "print(\"CV score is:\", gbc_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.4, 'max_depth': 2, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        'n_estimators': [4, 5, 6, 7, 8, 9, 10],\n",
    "        'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    }\n",
    "grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_d, y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.818176124651\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=2, learning_rate=0.4, n_estimators=8)\n",
    "xgb_score = cross_val_score(xgb, train_d, y, cv=5)\n",
    "print(\"CV score is:\", xgb_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.794554943334\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "logr_score = cross_val_score(logr, train_d, y, cv=5)\n",
    "print(\"CV score is:\", logr_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.812633826598\n"
     ]
    }
   ],
   "source": [
    "stacked_average_models = StackingAveragedModels(base_models=(svc, dtree, rfr, gbc, xgb), meta_model=logr)\n",
    "stack_score = cross_val_score(stacked_average_models, train_d, y, cv=5)\n",
    "print(\"CV score is:\", stack_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_average_models.fit(train_d, y)\n",
    "y_pred = stacked_average_models.predict(test_d)\n",
    "\n",
    "t = pd.read_csv(\"test.csv\")\n",
    "sub = pd.DataFrame()\n",
    "sub['PassengerId'] = t['PassengerId']\n",
    "sub['Survived'] = y_pred\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
